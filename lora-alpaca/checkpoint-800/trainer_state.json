{
  "best_metric": 0.9164844155311584,
  "best_model_checkpoint": "./lora-alpaca/checkpoint-800",
  "epoch": 2.0478361731061514,
  "eval_steps": 200,
  "global_step": 800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.025597952163826893,
      "grad_norm": 1.026565670967102,
      "learning_rate": 2.6999999999999996e-05,
      "loss": 2.3089,
      "step": 10
    },
    {
      "epoch": 0.051195904327653786,
      "grad_norm": 1.1835700273513794,
      "learning_rate": 5.6999999999999996e-05,
      "loss": 2.2146,
      "step": 20
    },
    {
      "epoch": 0.07679385649148068,
      "grad_norm": 0.9460681080818176,
      "learning_rate": 8.699999999999999e-05,
      "loss": 1.9955,
      "step": 30
    },
    {
      "epoch": 0.10239180865530757,
      "grad_norm": 1.2726478576660156,
      "learning_rate": 0.00010799999999999998,
      "loss": 1.5331,
      "step": 40
    },
    {
      "epoch": 0.12798976081913446,
      "grad_norm": 0.37890127301216125,
      "learning_rate": 0.000138,
      "loss": 1.2477,
      "step": 50
    },
    {
      "epoch": 0.15358771298296137,
      "grad_norm": 0.24856355786323547,
      "learning_rate": 0.000168,
      "loss": 1.1223,
      "step": 60
    },
    {
      "epoch": 0.17918566514678827,
      "grad_norm": 0.22660818696022034,
      "learning_rate": 0.000198,
      "loss": 1.0613,
      "step": 70
    },
    {
      "epoch": 0.20478361731061515,
      "grad_norm": 0.14433439075946808,
      "learning_rate": 0.00022799999999999999,
      "loss": 1.0456,
      "step": 80
    },
    {
      "epoch": 0.23038156947444205,
      "grad_norm": 0.15715137124061584,
      "learning_rate": 0.000258,
      "loss": 1.0244,
      "step": 90
    },
    {
      "epoch": 0.2559795216382689,
      "grad_norm": 0.1526031494140625,
      "learning_rate": 0.00028799999999999995,
      "loss": 1.0134,
      "step": 100
    },
    {
      "epoch": 0.28157747380209586,
      "grad_norm": 0.15376541018486023,
      "learning_rate": 0.00029831775700934576,
      "loss": 1.002,
      "step": 110
    },
    {
      "epoch": 0.30717542596592273,
      "grad_norm": 0.1983412206172943,
      "learning_rate": 0.0002955140186915888,
      "loss": 1.0025,
      "step": 120
    },
    {
      "epoch": 0.3327733781297496,
      "grad_norm": 0.2686760425567627,
      "learning_rate": 0.00029271028037383174,
      "loss": 0.981,
      "step": 130
    },
    {
      "epoch": 0.35837133029357654,
      "grad_norm": 0.49249860644340515,
      "learning_rate": 0.00028990654205607476,
      "loss": 0.9514,
      "step": 140
    },
    {
      "epoch": 0.3839692824574034,
      "grad_norm": 0.2936551868915558,
      "learning_rate": 0.00028738317757009345,
      "loss": 0.9484,
      "step": 150
    },
    {
      "epoch": 0.4095672346212303,
      "grad_norm": 0.5423261523246765,
      "learning_rate": 0.00028457943925233646,
      "loss": 0.9429,
      "step": 160
    },
    {
      "epoch": 0.4351651867850572,
      "grad_norm": 0.21487805247306824,
      "learning_rate": 0.0002817757009345794,
      "loss": 0.9504,
      "step": 170
    },
    {
      "epoch": 0.4607631389488841,
      "grad_norm": 2.1686019897460938,
      "learning_rate": 0.00027897196261682244,
      "loss": 0.9352,
      "step": 180
    },
    {
      "epoch": 0.486361091112711,
      "grad_norm": 0.18626584112644196,
      "learning_rate": 0.0002761682242990654,
      "loss": 0.9398,
      "step": 190
    },
    {
      "epoch": 0.5119590432765379,
      "grad_norm": 1.0331519842147827,
      "learning_rate": 0.0002733644859813084,
      "loss": 0.9406,
      "step": 200
    },
    {
      "epoch": 0.5119590432765379,
      "eval_loss": 0.938957691192627,
      "eval_runtime": 72.9241,
      "eval_samples_per_second": 27.426,
      "eval_steps_per_second": 3.428,
      "step": 200
    },
    {
      "epoch": 0.5375569954403647,
      "grad_norm": 2.0905866622924805,
      "learning_rate": 0.0002705607476635514,
      "loss": 0.932,
      "step": 210
    },
    {
      "epoch": 0.5631549476041917,
      "grad_norm": 0.1941591203212738,
      "learning_rate": 0.0002677570093457944,
      "loss": 0.9302,
      "step": 220
    },
    {
      "epoch": 0.5887528997680186,
      "grad_norm": 0.27555766701698303,
      "learning_rate": 0.00026495327102803737,
      "loss": 0.9291,
      "step": 230
    },
    {
      "epoch": 0.6143508519318455,
      "grad_norm": 1.3476366996765137,
      "learning_rate": 0.0002621495327102804,
      "loss": 0.9108,
      "step": 240
    },
    {
      "epoch": 0.6399488040956723,
      "grad_norm": 2.512050151824951,
      "learning_rate": 0.00025934579439252335,
      "loss": 0.9467,
      "step": 250
    },
    {
      "epoch": 0.6655467562594992,
      "grad_norm": 6.380815029144287,
      "learning_rate": 0.00025654205607476637,
      "loss": 0.9855,
      "step": 260
    },
    {
      "epoch": 0.6911447084233261,
      "grad_norm": 41.91986083984375,
      "learning_rate": 0.00025373831775700933,
      "loss": 1.7972,
      "step": 270
    },
    {
      "epoch": 0.7167426605871531,
      "grad_norm": 19.26081657409668,
      "learning_rate": 0.000251214953271028,
      "loss": 2.2546,
      "step": 280
    },
    {
      "epoch": 0.74234061275098,
      "grad_norm": 4.708612442016602,
      "learning_rate": 0.00024841121495327103,
      "loss": 1.4676,
      "step": 290
    },
    {
      "epoch": 0.7679385649148068,
      "grad_norm": 0.21689221262931824,
      "learning_rate": 0.000245607476635514,
      "loss": 1.0198,
      "step": 300
    },
    {
      "epoch": 0.7935365170786337,
      "grad_norm": 0.21026380360126495,
      "learning_rate": 0.000242803738317757,
      "loss": 0.9429,
      "step": 310
    },
    {
      "epoch": 0.8191344692424606,
      "grad_norm": 3.6546010971069336,
      "learning_rate": 0.00023999999999999998,
      "loss": 0.9595,
      "step": 320
    },
    {
      "epoch": 0.8447324214062875,
      "grad_norm": 4.511422634124756,
      "learning_rate": 0.00023719626168224297,
      "loss": 0.9696,
      "step": 330
    },
    {
      "epoch": 0.8703303735701144,
      "grad_norm": 83.40918731689453,
      "learning_rate": 0.00023467289719626168,
      "loss": 1.3649,
      "step": 340
    },
    {
      "epoch": 0.8959283257339413,
      "grad_norm": NaN,
      "learning_rate": 0.00023271028037383175,
      "loss": 2.1564,
      "step": 350
    },
    {
      "epoch": 0.9215262778977682,
      "grad_norm": 953.1759033203125,
      "learning_rate": 0.00023074766355140185,
      "loss": 2.9261,
      "step": 360
    },
    {
      "epoch": 0.9471242300615951,
      "grad_norm": 915.0687255859375,
      "learning_rate": 0.00022794392523364484,
      "loss": 4.6327,
      "step": 370
    },
    {
      "epoch": 0.972722182225422,
      "grad_norm": 190.4476776123047,
      "learning_rate": 0.00022514018691588783,
      "loss": 3.381,
      "step": 380
    },
    {
      "epoch": 0.9983201343892488,
      "grad_norm": 2.3309988975524902,
      "learning_rate": 0.00022233644859813082,
      "loss": 1.5354,
      "step": 390
    },
    {
      "epoch": 1.0239180865530757,
      "grad_norm": 0.3750405013561249,
      "learning_rate": 0.0002195327102803738,
      "loss": 0.9837,
      "step": 400
    },
    {
      "epoch": 1.0239180865530757,
      "eval_loss": 0.958755612373352,
      "eval_runtime": 72.9769,
      "eval_samples_per_second": 27.406,
      "eval_steps_per_second": 3.426,
      "step": 400
    },
    {
      "epoch": 1.0495160387169027,
      "grad_norm": 0.19860470294952393,
      "learning_rate": 0.0002167289719626168,
      "loss": 0.9492,
      "step": 410
    },
    {
      "epoch": 1.0751139908807295,
      "grad_norm": 0.2158309668302536,
      "learning_rate": 0.0002139252336448598,
      "loss": 0.9327,
      "step": 420
    },
    {
      "epoch": 1.1007119430445564,
      "grad_norm": 0.20185354351997375,
      "learning_rate": 0.00021112149532710278,
      "loss": 0.9271,
      "step": 430
    },
    {
      "epoch": 1.1263098952083834,
      "grad_norm": 0.18552939593791962,
      "learning_rate": 0.00020831775700934577,
      "loss": 0.9284,
      "step": 440
    },
    {
      "epoch": 1.1519078473722102,
      "grad_norm": 0.16108645498752594,
      "learning_rate": 0.00020551401869158876,
      "loss": 0.9305,
      "step": 450
    },
    {
      "epoch": 1.1775057995360372,
      "grad_norm": 0.20924322307109833,
      "learning_rate": 0.00020271028037383175,
      "loss": 0.9231,
      "step": 460
    },
    {
      "epoch": 1.203103751699864,
      "grad_norm": 0.1658041775226593,
      "learning_rate": 0.00019990654205607474,
      "loss": 0.934,
      "step": 470
    },
    {
      "epoch": 1.228701703863691,
      "grad_norm": 0.18964973092079163,
      "learning_rate": 0.00019710280373831773,
      "loss": 0.9245,
      "step": 480
    },
    {
      "epoch": 1.2542996560275177,
      "grad_norm": 0.15814775228500366,
      "learning_rate": 0.00019429906542056072,
      "loss": 0.918,
      "step": 490
    },
    {
      "epoch": 1.2798976081913447,
      "grad_norm": 0.1722109615802765,
      "learning_rate": 0.00019149532710280371,
      "loss": 0.9254,
      "step": 500
    },
    {
      "epoch": 1.3054955603551717,
      "grad_norm": 0.5540277361869812,
      "learning_rate": 0.0001886915887850467,
      "loss": 0.9279,
      "step": 510
    },
    {
      "epoch": 1.3310935125189984,
      "grad_norm": 0.1563752144575119,
      "learning_rate": 0.0001858878504672897,
      "loss": 0.938,
      "step": 520
    },
    {
      "epoch": 1.3566914646828254,
      "grad_norm": 0.1534145623445511,
      "learning_rate": 0.00018308411214953269,
      "loss": 0.9239,
      "step": 530
    },
    {
      "epoch": 1.3822894168466522,
      "grad_norm": 0.1657055765390396,
      "learning_rate": 0.00018028037383177568,
      "loss": 0.9235,
      "step": 540
    },
    {
      "epoch": 1.4078873690104792,
      "grad_norm": 0.1758132427930832,
      "learning_rate": 0.00017747663551401867,
      "loss": 0.9097,
      "step": 550
    },
    {
      "epoch": 1.433485321174306,
      "grad_norm": 0.13774889707565308,
      "learning_rate": 0.00017467289719626166,
      "loss": 0.9259,
      "step": 560
    },
    {
      "epoch": 1.459083273338133,
      "grad_norm": 0.14605848491191864,
      "learning_rate": 0.00017186915887850465,
      "loss": 0.901,
      "step": 570
    },
    {
      "epoch": 1.48468122550196,
      "grad_norm": 0.15259380638599396,
      "learning_rate": 0.00016906542056074764,
      "loss": 0.9197,
      "step": 580
    },
    {
      "epoch": 1.5102791776657867,
      "grad_norm": 0.21946318447589874,
      "learning_rate": 0.00016626168224299063,
      "loss": 0.911,
      "step": 590
    },
    {
      "epoch": 1.5358771298296137,
      "grad_norm": 0.1828104555606842,
      "learning_rate": 0.00016345794392523362,
      "loss": 0.9068,
      "step": 600
    },
    {
      "epoch": 1.5358771298296137,
      "eval_loss": 0.9218301773071289,
      "eval_runtime": 73.173,
      "eval_samples_per_second": 27.333,
      "eval_steps_per_second": 3.417,
      "step": 600
    },
    {
      "epoch": 1.5614750819934407,
      "grad_norm": 0.1578707993030548,
      "learning_rate": 0.0001606542056074766,
      "loss": 0.9217,
      "step": 610
    },
    {
      "epoch": 1.5870730341572674,
      "grad_norm": 0.16274616122245789,
      "learning_rate": 0.0001578504672897196,
      "loss": 0.9148,
      "step": 620
    },
    {
      "epoch": 1.6126709863210942,
      "grad_norm": 0.1681460589170456,
      "learning_rate": 0.0001550467289719626,
      "loss": 0.9052,
      "step": 630
    },
    {
      "epoch": 1.6382689384849212,
      "grad_norm": 0.16915377974510193,
      "learning_rate": 0.00015224299065420558,
      "loss": 0.8982,
      "step": 640
    },
    {
      "epoch": 1.6638668906487482,
      "grad_norm": 0.1722339540719986,
      "learning_rate": 0.00014943925233644857,
      "loss": 0.9215,
      "step": 650
    },
    {
      "epoch": 1.689464842812575,
      "grad_norm": 0.1529165357351303,
      "learning_rate": 0.00014663551401869156,
      "loss": 0.9111,
      "step": 660
    },
    {
      "epoch": 1.715062794976402,
      "grad_norm": 0.15425828099250793,
      "learning_rate": 0.00014383177570093456,
      "loss": 0.9152,
      "step": 670
    },
    {
      "epoch": 1.740660747140229,
      "grad_norm": 0.18001452088356018,
      "learning_rate": 0.00014102803738317755,
      "loss": 0.9163,
      "step": 680
    },
    {
      "epoch": 1.7662586993040557,
      "grad_norm": 0.24195097386837006,
      "learning_rate": 0.00013822429906542054,
      "loss": 0.9077,
      "step": 690
    },
    {
      "epoch": 1.7918566514678824,
      "grad_norm": 0.16937100887298584,
      "learning_rate": 0.00013542056074766353,
      "loss": 0.9204,
      "step": 700
    },
    {
      "epoch": 1.8174546036317094,
      "grad_norm": 0.40990936756134033,
      "learning_rate": 0.00013261682242990655,
      "loss": 0.9085,
      "step": 710
    },
    {
      "epoch": 1.8430525557955364,
      "grad_norm": 0.20214340090751648,
      "learning_rate": 0.00012981308411214954,
      "loss": 0.907,
      "step": 720
    },
    {
      "epoch": 1.8686505079593632,
      "grad_norm": 0.3008922338485718,
      "learning_rate": 0.00012700934579439253,
      "loss": 0.9114,
      "step": 730
    },
    {
      "epoch": 1.8942484601231901,
      "grad_norm": 0.1779537796974182,
      "learning_rate": 0.00012420560747663552,
      "loss": 0.9119,
      "step": 740
    },
    {
      "epoch": 1.9198464122870171,
      "grad_norm": 0.1958608329296112,
      "learning_rate": 0.0001214018691588785,
      "loss": 0.9194,
      "step": 750
    },
    {
      "epoch": 1.945444364450844,
      "grad_norm": 47.47478103637695,
      "learning_rate": 0.00011859813084112148,
      "loss": 0.9154,
      "step": 760
    },
    {
      "epoch": 1.9710423166146707,
      "grad_norm": 0.29108309745788574,
      "learning_rate": 0.00011579439252336448,
      "loss": 0.9277,
      "step": 770
    },
    {
      "epoch": 1.9966402687784979,
      "grad_norm": 0.20308709144592285,
      "learning_rate": 0.00011299065420560747,
      "loss": 0.8977,
      "step": 780
    },
    {
      "epoch": 2.0222382209423246,
      "grad_norm": 0.1785682588815689,
      "learning_rate": 0.00011018691588785046,
      "loss": 0.8967,
      "step": 790
    },
    {
      "epoch": 2.0478361731061514,
      "grad_norm": 0.17785108089447021,
      "learning_rate": 0.00010738317757009345,
      "loss": 0.9115,
      "step": 800
    },
    {
      "epoch": 2.0478361731061514,
      "eval_loss": 0.9164844155311584,
      "eval_runtime": 74.0822,
      "eval_samples_per_second": 26.997,
      "eval_steps_per_second": 3.375,
      "step": 800
    }
  ],
  "logging_steps": 10,
  "max_steps": 1170,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.582261900797542e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
